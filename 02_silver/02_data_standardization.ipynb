{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd2bb792-700d-4956-9823-7bf034626a9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00de8618-7828-4b46-8514-ebf5db9328bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------\n",
    "# REUSABLE FUNCTION TO FILL NON-BUSINESS NULLS WITH DEFAULT VALUES\n",
    "# -------------------------------------------------------------------\n",
    "from pyspark.sql.types import (\n",
    "    StringType, IntegerType, LongType,\n",
    "    DoubleType, TimestampType, DateType\n",
    ")\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def fill_non_business_nulls(df, business_keys):\n",
    "    fill_map = {}\n",
    "    timestamp_cols = []\n",
    "\n",
    "    for field in df.schema.fields:\n",
    "        col_name = field.name\n",
    "        col_type = field.dataType\n",
    "\n",
    "        if col_name not in business_keys:\n",
    "            if isinstance(col_type, StringType):\n",
    "                fill_map[col_name] = \"UNKNOWN\"\n",
    "\n",
    "            elif isinstance(col_type, (IntegerType, LongType)):\n",
    "                fill_map[col_name] = 0\n",
    "\n",
    "            elif isinstance(col_type, DoubleType):\n",
    "                fill_map[col_name] = 0.0\n",
    "\n",
    "            elif isinstance(col_type, (TimestampType, DateType)):\n",
    "                timestamp_cols.append(col_name)\n",
    "\n",
    "    # ----------------------------\n",
    "    # Fill NON-BUSINESS NULLS\n",
    "    # ----------------------------\n",
    "    df = df.fillna(fill_map)\n",
    "\n",
    "    # ------------------------------------------\n",
    "    # Fill TIMESTAMPS with CURRENT_TIMESTAMP\n",
    "    # ------------------------------------------\n",
    "    for col in timestamp_cols:\n",
    "        df = df.withColumn(\n",
    "            col,\n",
    "            F.when(F.col(col).isNull(), F.current_timestamp())\n",
    "             .otherwise(F.col(col))\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3f905fb-04b1-4336-b42c-8f8321da6ad9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ------------------------------------------\n",
    "# ENFORCE SCHEMA AND DEFINE BUSINEES KEYS\n",
    "# ------------------------------------------\n",
    "customers_keys = [\"customer_id\"]\n",
    "customers_schema = {\n",
    "    \"customer_id\": \"string\",\n",
    "    \"customer_unique_id\": \"string\",\n",
    "    \"customer_zip_code_prefix\": \"int\",\n",
    "    \"customer_city\": \"string\",\n",
    "    \"customer_state\": \"string\"\n",
    "}\n",
    "\n",
    "products_keys = [\"product_id\"]\n",
    "products_schema = {\n",
    "    \"product_id\": \"string\",\n",
    "    \"product_category_name\": \"string\",\n",
    "    \"product_name_length\": \"int\",\n",
    "    \"product_description_length\": \"int\",\n",
    "    \"product_photos_qty\": \"int\",\n",
    "    \"product_weight_g\": \"int\",\n",
    "    \"product_length_cm\": \"int\",\n",
    "    \"product_height_cm\": \"int\",\n",
    "    \"product_width_cm\": \"int\"\n",
    "}\n",
    "\n",
    "order_items_keys = [\"order_id\",\"order_item_id\"]\n",
    "order_items_schema = {\n",
    "    \"order_id\": \"string\",\n",
    "    \"order_item_id\": \"string\",\n",
    "    \"product_id\": \"string\",\n",
    "    \"seller_id\": \"string\",\n",
    "    \"shipping_limit_date\" : \"timestamp\",\n",
    "    \"price\": \"double\",\n",
    "    \"freight_value\": \"double\"\n",
    "}\n",
    "\n",
    "orders_keys = [\"order_id\", \"customer_id\"]\n",
    "orders_schema = {\n",
    "    \"order_id\": \"string\",\n",
    "    \"customer_id\": \"string\",\n",
    "    \"order_status\": \"string\",\n",
    "    \"order_purchase_timestamp\": \"timestamp\",\n",
    "    \"order_approved_at\": \"timestamp\",\n",
    "    \"order_delivered_carrier_date\": \"timestamp\",\n",
    "    \"order_delivered_customer_date\": \"timestamp\",\n",
    "    \"order_estimated_delivery_date\": \"timestamp\"\n",
    "}\n",
    "\n",
    "orders_payments_keys = [\"order_id\", \"payment_sequential\"]\n",
    "orders_payments_schema = {\n",
    "    \"order_id\": \"string\",\n",
    "    \"payment_sequential\": \"int\",\n",
    "    \"payment_type\": \"string\",\n",
    "    \"payment_installments\": \"int\",\n",
    "    \"payment_value\": \"double\"\n",
    "}\n",
    "\n",
    "products_keys = [\"product_id\"]\n",
    "products_schema = {\n",
    "    \"product_id\": \"string\",\n",
    "    \"product_category_name\": \"string\",\n",
    "    \"product_name_lenght\": \"int\",\n",
    "    \"product_description_lenght\": \"int\",\n",
    "    \"product_photos_qty\": \"int\",\n",
    "    \"product_weight_g\": \"integer\",\n",
    "    \"product_length_cm\": \"integer\",\n",
    "    \"product_height_cm\": \"integer\",\n",
    "    \"product_width_cm\": \"integer\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45609e9a-6ca9-4f78-9912-566e934460c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --------------------------------------\n",
    "# REUSEABL FUNCTION TO PROCESS TABLES\n",
    "# --------------------------------------\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "def process_table(\n",
    "    table_name,\n",
    "    bronze_path,\n",
    "    silver_table,\n",
    "    schema_dict,\n",
    "    business_keys,\n",
    "    partition_col=None,\n",
    "    zorder_cols=None\n",
    "):\n",
    "    print(f\"===== Processing {table_name} =====\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # 1. Read Bronze (PARQUET)\n",
    "    # ----------------------------\n",
    "    df = spark.read.parquet(bronze_path)\n",
    "\n",
    "    # -------------------\n",
    "    # 2. Cast columns\n",
    "    # -------------------\n",
    "    for col, dtype in schema_dict.items():\n",
    "        df = df.withColumn(col, F.col(col).cast(dtype))\n",
    "\n",
    "    # -------------------------------\n",
    "    # 3. Add ingestion timestamp\n",
    "    # -------------------------------\n",
    "    df = df.withColumn(\"ingestion_ts\", F.current_timestamp())\n",
    "    df = df.withColumn(\"ingestion_date\", F.to_date(\"ingestion_ts\"))\n",
    "\n",
    "    # ------------------------\n",
    "    # 4. NULL count BEFORE\n",
    "    # ------------------------\n",
    "    def count_nulls(df):\n",
    "        return df.select([\n",
    "        F.count(F.when(F.col(c).isNull(), c)).alias(c + \"_nulls\")\n",
    "        for c in df.columns\n",
    "    ])\n",
    "    display(count_nulls(df))\n",
    "\n",
    "    # ----------------------\n",
    "    # 5. Dedup & cleanse\n",
    "    # ----------------------\n",
    "    def cleanse_business_keys(\n",
    "        df,\n",
    "        business_keys\n",
    "    ):\n",
    "        # Drop rows where any business key is null\n",
    "        for key in business_keys:\n",
    "            df = df.filter(df[key].isNotNull())\n",
    "        # Drop duplicate rows based on business keys\n",
    "        df = df.dropDuplicates(business_keys)\n",
    "        return df\n",
    "\n",
    "    df = cleanse_business_keys(df, business_keys)\n",
    "    df = fill_non_business_nulls(df, business_keys)\n",
    "\n",
    "    # ----------------------------------------\n",
    "    # 6. Write Silver Delta (Partitioned)\n",
    "    # ----------------------------------------\n",
    "    writer = (\n",
    "        df.write\n",
    "          .format(\"delta\")\n",
    "          .mode(\"overwrite\")\n",
    "    )\n",
    "\n",
    "    if partition_col:\n",
    "        writer = writer.partitionBy(partition_col)\n",
    "\n",
    "    writer.saveAsTable(silver_table)\n",
    "\n",
    "    # --------------------------\n",
    "    # 7. OPTIMIZE (Z-ORDER)\n",
    "    # --------------------------\n",
    "    if zorder_cols:\n",
    "        spark.sql(\n",
    "            f\"OPTIMIZE {silver_table} ZORDER BY ({','.join(zorder_cols)})\"\n",
    "        )\n",
    "\n",
    "    print(f\"===== {table_name} Completed =====\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a15237b-0440-49e5-8da3-1540a09f4301",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# PROCESS TABLES\n",
    "\n",
    "process_table(\n",
    "    table_name=\"customers\",\n",
    "    bronze_path=\"/Volumes/real_time_projects/ecommerce_historical/lakehouse_vol/bronze/customers\",\n",
    "    silver_table=\"real_time_projects.ecommerce_historical.customers\",\n",
    "    schema_dict=customers_schema,\n",
    "    business_keys=customers_keys,\n",
    "    partition_col=\"customer_state\",\n",
    "    zorder_cols=customers_keys\n",
    ")\n",
    "\n",
    "process_table(\n",
    "    table_name=\"orders\",\n",
    "    bronze_path=\"/Volumes/real_time_projects/ecommerce_historical/lakehouse_vol/bronze/orders\",\n",
    "    silver_table=\"real_time_projects.ecommerce_historical.orders\",\n",
    "    schema_dict=orders_schema,\n",
    "    business_keys=orders_keys,\n",
    "    partition_col=\"order_status\",\n",
    "    zorder_cols=orders_keys\n",
    ")   \n",
    "\n",
    "process_table(\n",
    "    table_name=\"products\",\n",
    "    bronze_path=\"/Volumes/real_time_projects/ecommerce_historical/lakehouse_vol/bronze/products\",\n",
    "    silver_table=\"real_time_projects.ecommerce_historical.products\",\n",
    "    schema_dict=products_schema,\n",
    "    business_keys=products_keys,\n",
    "    partition_col=\"product_category_name\",\n",
    "    zorder_cols=products_keys\n",
    ")\n",
    "\n",
    "process_table(\n",
    "    table_name=\"order_items\",\n",
    "    bronze_path=\"/Volumes/real_time_projects/ecommerce_historical/lakehouse_vol/bronze/order_items\",\n",
    "    silver_table=\"real_time_projects.ecommerce_historical.order_items\",\n",
    "    schema_dict=order_items_schema,\n",
    "    business_keys=order_items_keys,\n",
    "    partition_col=\"ingestion_date\",\n",
    "    zorder_cols=order_items_keys\n",
    ")\n",
    "\n",
    "process_table(\n",
    "    table_name=\"order_payments\",\n",
    "    bronze_path=\"/Volumes/real_time_projects/ecommerce_historical/lakehouse_vol/bronze/payments\",\n",
    "    silver_table=\"real_time_projects.ecommerce_historical.order_payments\",\n",
    "    schema_dict=orders_payments_schema,\n",
    "    business_keys=orders_payments_keys,\n",
    "    partition_col=\"ingestion_date\",\n",
    "    zorder_cols=orders_payments_keys\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_data_standardization",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
